{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "# Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T10:06:42.379809Z",
     "start_time": "2020-09-08T10:06:42.363910Z"
    }
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "from spacy import displacy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T08:07:30.830942Z",
     "start_time": "2020-09-08T08:07:30.805466Z"
    }
   },
   "outputs": [],
   "source": [
    "def readXML(dataPath):\n",
    "    sb = []\n",
    "    root = ET.parse(dataPath).getroot()    \n",
    "    for child in root[0]: \n",
    "        if child.tag == 'item': \n",
    "            s = child.find('description').text\n",
    "            s = re.findall(\"<img.*/><p>(.+)</p>\",s)\n",
    "            sb.append(s[0])\n",
    "    return sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T08:08:41.944137Z",
     "start_time": "2020-09-08T08:08:41.926220Z"
    }
   },
   "outputs": [],
   "source": [
    "xml = readXML(\"./Data/European Investment Bank Press Releases/data/English_Press-releases.xml\")\n",
    "xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "#### Ex. 1.1: Load the small spaCy model for English which has been trained on web documents "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "Hint: This model is called *en_core_web_sm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T08:16:47.988731Z",
     "start_time": "2020-09-08T08:16:46.708655Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown",
    "solution_first": true
   },
   "source": [
    "#### Ex 1.2: Create a document that has been annotated with named entities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T08:18:11.068496Z",
     "start_time": "2020-09-08T08:18:11.028550Z"
    },
    "solution": "shown"
   },
   "source": [
    "Hint: simply call the Language object *nlp* with your text. This will trigger the whole processing pipeline to run  \n",
    "Hint 2: You cannot give it the array of strings directly, but either have to process each item separately or have to join the separate strings into 1 large one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T09:14:36.833953Z",
     "start_time": "2020-09-08T09:14:36.679023Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "#### Ex 1.3: Highlight the name entities in the text using spaCy's package \"displacy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "Hint: use method *render* of displacy and set the style to named entities (*ent*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T08:16:55.618828Z",
     "start_time": "2020-09-08T08:16:55.588902Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex. 1.4: Are there some abbreviations for the named entities that you don't know? You can get an explanation for them using spaCy's *explain* method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ex 2.1: Next, we are going to visualize the text as a word cloud. Run the code below. Does it help you to get an idea of the content of the documents? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T08:44:18.448541Z",
     "start_time": "2020-09-08T08:44:10.330378Z"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 2000, height = 2000, background_color = \"white\").generate(\" \".join(xml))\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.imshow(wordcloud, interpolation = \"bilinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown",
    "solution_first": true
   },
   "source": [
    "#### Ex 2.2: Create a word cloud visualizing only the counts of the names of organizations in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "shown"
   },
   "source": [
    "Hint: first you must combine all named entities into a single string. You can get access to the named entities via the attribute *ents* of the spaCy document. Loop over the values and collect all of them in a separate variable that have been tagged as an organization (tag *ORG*)  \n",
    "Hint 2: If you want to have multi-term phrases being kept together in the word cloud you must create a dictionary in the form {phrase: count, ...} and use method *generate_from_frequencies* instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T08:54:43.561526Z",
     "start_time": "2020-09-08T08:54:43.551403Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T08:54:49.179161Z",
     "start_time": "2020-09-08T08:54:45.961380Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden"
   },
   "source": [
    "### More Tasks (only if time permits; choose the one(s) you like best)\n",
    "\n",
    "<b>1. Load and process text in French or German  </b>  \n",
    "The same data set is also available in French and German. Load and process the data. \n",
    "Compare the results with the English ones. How is the quality of the results? \n",
    "\n",
    "<b>2. Apply NER to the job posts</b>  \n",
    "How good is the quality of the results for this data set? Do you have an explanation for some of the errors that are made? \n",
    "\n",
    "<b>3. Extract all adjectives or all nouns of the texts and visualize them in a word cloud </b>  \n",
    "Hint: spaCy did not only extract the named entities when you called nlp() but it also tagged the parts of speech in the document already. You can access them via the attribute *pos_* of the tokens of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
